# Detector AutomÃ¡tico de MÃ©todos de OptimizaciÃ³n

Este mÃ³dulo implementa un sistema automÃ¡tico para determinar quÃ© mÃ©todo de optimizaciÃ³n usar basÃ¡ndose en el enunciado de un problema.

## ğŸ¯ Objetivo

Dado un enunciado o ejercicio, el sistema:
1. **Determina automÃ¡ticamente** quÃ© mÃ©todo usar (Gradiente, KKT, Lagrange, QP, o Diferencial)
2. **Extrae los parÃ¡metros** necesarios en formato JSON
3. **Explica por quÃ©** se eligiÃ³ ese mÃ©todo

## ğŸ“‹ Las 5 Reglas de SelecciÃ³n

El sistema aplica estas reglas **en orden estricto**:

### Regla 1: Proceso Iterativo â†’ GRADIENTE

**Si el problema menciona pasos repetidos**, usa el mÃ©todo del gradiente.

**Palabras clave:**
- iterar, iterativo, iteraciÃ³n
- descenso del gradiente
- actualizar, paso Î±
- tasa de aprendizaje
- entrenamiento
- varias iteraciones
- repetir el cÃ¡lculo

**Ejemplo:**
```
Minimizar f(x,y) = xÂ² + yÂ² usando descenso del gradiente.
Punto inicial: x0 = [1, 1]
Î± = 0.1
100 iteraciones
```
â†’ **GRADIENTE**

---

### Regla 2: Restricciones No Lineales â†’ KKT

**Si hay al menos UNA restricciÃ³n no lineal**, usa condiciones KKT.

**No lineal = tiene:**
- Cuadrados: xÂ², yÂ²
- Productos de variables: xy
- RaÃ­ces: âˆšx
- Divisiones: x/y
- Cualquier cosa que NO sea solo sumar/restar/multiplicar por nÃºmeros

**Ejemplo:**
```
Minimizar f(x,y) = x + y
sujeto a:
  xÂ² + yÂ² â‰¤ 10    â† NO LINEAL (tiene cuadrados)
  x â‰¥ 0
```
â†’ **KKT**

---

### Regla 3: Solo Igualdades â†’ LAGRANGE

**Si todas las restricciones son igualdades**, usa multiplicadores de Lagrange.

**Requisitos:**
- Debe haber al menos UNA restricciÃ³n
- TODAS deben ser igualdades (=)
- NINGUNA puede ser desigualdad (â‰¤, â‰¥)

**Ejemplo:**
```
Minimizar f(x,y,z) = xÂ² + yÂ² + zÂ²
sujeto a:
  x + y + z = 100    â† IGUALDAD
  2x - y = 10        â† IGUALDAD
```
â†’ **LAGRANGE**

---

### Regla 4: FunciÃ³n CuadrÃ¡tica + Restricciones Lineales â†’ QP

**Si la funciÃ³n objetivo es cuadrÃ¡tica Y todas las restricciones son lineales**, usa ProgramaciÃ³n CuadrÃ¡tica.

**Requisitos:**
- FunciÃ³n objetivo tiene tÃ©rminos cuadrÃ¡ticos (xÂ², yÂ²)
- TODAS las restricciones son lineales (solo x, y, constantes)
- Debe haber AL MENOS una restricciÃ³n

**Ejemplo:**
```
Minimizar f(x,y) = xÂ² + yÂ² + xy - 4x - 5y
sujeto a:
  x + y â‰¤ 10       â† LINEAL
  2x + y â‰¤ 15      â† LINEAL
  x â‰¥ 0            â† LINEAL
```
â†’ **QP**

---

### Regla 5: Sin Restricciones

**Si NO hay restricciones:**

#### 5a: Pide derivadas â†’ DIFERENCIAL
Si menciona: puntos crÃ­ticos, derivadas, mÃ¡ximos, mÃ­nimos, equilibrio

**Ejemplo:**
```
Encontrar los puntos crÃ­ticos de f(x,y) = xÂ³ - 3xy + yÂ²
Calcular las derivadas parciales.
```
â†’ **DIFERENCIAL**

#### 5b: Solo optimizaciÃ³n â†’ GRADIENTE
Si solo dice minimizar/maximizar sin mencionar derivadas

**Ejemplo:**
```
Minimizar f(x,y) = xÂ² + 2yÂ² - 4x - 6y + 10
```
â†’ **GRADIENTE**

---

## ğŸ’» Uso del Sistema

### Uso BÃ¡sico

```python
from opti_app.core.message_parser import parse_and_determine_method

# Tu problema
problema = """
Minimizar f(x,y) = xÂ² + yÂ²
sujeto a:
  xÂ² + y â‰¤ 10
  x â‰¥ 0
"""

# Analizar
resultado = parse_and_determine_method(problema)

# Ver resultados
print(f"MÃ©todo: {resultado['method']}")
print(f"RazÃ³n: {resultado['method_explanation']['reason']}")
print(f"ParÃ¡metros: {resultado['solver_params']}")
```

### Salida Ejemplo

```json
{
  "method": "kkt",
  "method_explanation": {
    "reason": "El problema tiene al menos una restricciÃ³n no lineal (con cuadrados, productos de variables, raÃ­ces, etc.)",
    "rule_applied": 2
  },
  "solver_params": {
    "method": "kkt",
    "objective": "x**2 + y**2",
    "variables": ["x", "y"],
    "constraints": [
      {
        "kind": "le",
        "expr": "(x**2 + y) - (10)"
      },
      {
        "kind": "ge",
        "expr": "(x) - (0)"
      }
    ],
    "tol": 1e-06
  },
  "raw_data": {
    "objective_expr": "x**2 + y**2",
    "variables": ["x", "y"],
    "constraints": [...]
  }
}
```

## ğŸ”§ API Detallada

### `parse_and_determine_method(text: str)`

FunciÃ³n principal que analiza un problema completo.

**ParÃ¡metros:**
- `text`: Texto completo del problema

**Retorna:**
```python
{
    'method': str,  # 'gradient', 'kkt', 'lagrange', 'qp', 'differential'
    'method_explanation': {
        'reason': str,  # Por quÃ© se eligiÃ³ este mÃ©todo
        'rule_applied': int  # QuÃ© regla se aplicÃ³ (1-5)
    },
    'solver_params': {
        'method': str,
        'objective': str,
        'variables': List[str],
        'constraints': List[Dict],  # Si aplica
        'x0': List[float],  # Si aplica
        'tol': float,  # Si aplica
        'max_iter': int,  # Si aplica
        ...
    },
    'raw_data': Dict  # Datos parseados originales
}
```

### Funciones del MÃ³dulo `method_detector`

```python
from opti_app.core import method_detector

# Determinar solo el mÃ©todo
method = method_detector.determine_method(
    text="...",
    objective_expr="x**2 + y**2",
    constraints=[...]
)
# Retorna: 'gradient', 'kkt', 'lagrange', 'qp', o 'differential'

# Obtener explicaciÃ³n detallada
explanation = method_detector.explain_method_choice(
    text="...",
    objective_expr="...",
    constraints=[...]
)
# Retorna: {'method': ..., 'reason': ..., 'rule_applied': ...}

# Extraer parÃ¡metros para solver
params = method_detector.extract_solver_parameters(
    method='kkt',
    objective_expr='x**2 + y**2',
    constraints=[...],
    variables=['x', 'y'],
    x0=[1.0, 1.0],
    tol=1e-6
)
```

## ğŸ“ ParÃ¡metros ExtraÃ­dos por MÃ©todo

### GRADIENTE
```json
{
  "method": "gradient",
  "objective": "...",
  "variables": [...],
  "constraints": [...],
  "x0": [0.0, 0.0],
  "tol": 1e-6,
  "max_iter": 1000,
  "alpha": 0.01
}
```

### KKT
```json
{
  "method": "kkt",
  "objective": "...",
  "variables": [...],
  "constraints": [...],
  "x0": [...],  // opcional
  "tol": 1e-6
}
```

### LAGRANGE
```json
{
  "method": "lagrange",
  "objective": "...",
  "variables": [...],
  "constraints": [...],
  "x0": [...],  // opcional
  "tol": 1e-6
}
```

### QP (ProgramaciÃ³n CuadrÃ¡tica)
```json
{
  "method": "qp",
  "objective": "...",
  "variables": [...],
  "constraints": [...],
  "x0": [0.0, 0.0],
  "tol": 1e-6
}
```

### DIFERENCIAL
```json
{
  "method": "differential",
  "objective": "...",
  "variables": [...],
  "x0": [...]  // opcional
}
```

## ğŸ§ª Pruebas

Ejecuta el script de pruebas para ver ejemplos de cada regla:

```bash
cd opti_learn/opti_app/core
python test_method_detector.py
```

## ğŸ“ Ejemplos de Uso

### Ejemplo 1: Problema con iteraciones

```python
problema = """
Minimizar f(x,y) = xÂ² + yÂ²
usando descenso del gradiente con Î± = 0.01
Realizar 100 iteraciones desde x0 = [1, 1]
"""

resultado = parse_and_determine_method(problema)
# mÃ©todo: 'gradient'
# razÃ³n: "El problema menciona un proceso iterativo"
# regla: 1
```

### Ejemplo 2: Problema con restricciÃ³n no lineal

```python
problema = """
Maximizar f(x,y) = 2x + 3y
sujeto a: xy â‰¤ 100
"""

resultado = parse_and_determine_method(problema)
# mÃ©todo: 'kkt'
# razÃ³n: "El problema tiene al menos una restricciÃ³n no lineal"
# regla: 2
```

### Ejemplo 3: Solo igualdades

```python
problema = """
Minimizar f(x,y,z) = xÂ² + yÂ² + zÂ²
sujeto a:
  x + y + z = 100
  x - y = 0
"""

resultado = parse_and_determine_method(problema)
# mÃ©todo: 'lagrange'
# razÃ³n: "El problema tiene solo restricciones de igualdad"
# regla: 3
```

## ğŸ” CÃ³mo Funciona Internamente

1. **Parsing**: Se extrae la funciÃ³n objetivo, restricciones, variables, etc.
2. **DetecciÃ³n de mÃ©todo**: Se aplican las 5 reglas en orden
3. **ExtracciÃ³n de parÃ¡metros**: Se construye el JSON segÃºn el mÃ©todo
4. **ValidaciÃ³n**: Se verifican las expresiones con SymPy

### Flujo de DecisiÃ³n

```
Â¿Menciona proceso iterativo? â†’ GRADIENTE
     â†“ No
Â¿Hay restricciones no lineales? â†’ KKT
     â†“ No
Â¿Solo hay igualdades? â†’ LAGRANGE
     â†“ No
Â¿FunciÃ³n cuadrÃ¡tica + restricciones lineales? â†’ QP
     â†“ No
Â¿Hay restricciones?
     â†“ No
Â¿Pide derivadas? â†’ DIFERENCIAL
     â†“ No
GRADIENTE (por defecto)
```

## âš™ï¸ IntegraciÃ³n con el Asistente IA

Los prompts en `ai_prompts.py` han sido actualizados para que la IA tambiÃ©n use estas reglas:

```python
from opti_app.core.ai_prompts import PROMPT_METHOD_SELECTION

# Este prompt le indica a la IA cÃ³mo elegir el mÃ©todo
messages = [
    {"role": "system", "content": PROMPT_METHOD_SELECTION},
    {"role": "user", "content": problema_usuario}
]
```

## ğŸ“š Referencias

- **message_parser.py**: Parsing de texto a estructura
- **method_detector.py**: DetecciÃ³n de mÃ©todo y extracciÃ³n de parÃ¡metros
- **ai_prompts.py**: Prompts para el asistente IA
- **test_method_detector.py**: Suite de pruebas

## ğŸ› Troubleshooting

### El mÃ©todo detectado no es el esperado

Verifica que el problema cumpla EXACTAMENTE los criterios de la regla:
- Para LAGRANGE: NO puede haber desigualdades
- Para QP: TODAS las restricciones deben ser lineales
- Para KKT: Debe haber al menos UNA restricciÃ³n no lineal

### No se extraen los parÃ¡metros

AsegÃºrate de que el problema estÃ© bien formateado:
```
Minimizar f(x,y) = ...
sujeto a:
  restricciÃ³n1
  restricciÃ³n2
```

### Variables no detectadas

Especifica explÃ­citamente:
```
Variables: x, y, z
```

O usa nombres estÃ¡ndar (x, y, z, etc.)
